S3cmd S3 Sync How-To
====================
http://s3tools.org/s3cmd-sync

Program S3cmd can transfer files to and from Amazon S3 in two basic modes:

put/get - Unconditional transfer -- all matching files are uploaded to S3 (put operation) or downloaded back from S3 (get operation). This is similar to a standard unix cp command that also copies whatever it’s told to.

sync - Conditional transfer -- only files that don’t exist at the destination in the same version are transferred. By default a md5 checksum and file size is compared. This is similar to a unix rsync command, with some exceptions outlined below.

Filenames handling rules and some other options are common for both these methods.

Filenames handling rules
========================

Sync, get and put all support multiple arguments for source files and one argument for destination file or directory (optional in some case of get). The source can be a single file or a directory and there could be multiple sources used in one command.

Upload one of the files to S3 and give it a different name:
$ s3cmd put file0-1.msg s3://s3tools-demo/test-upload.msg
file0-1.msg -> s3://s3tools-demo/test-upload.msg  [1 of 1]

Upload a directory with --recursive parameter:
$ s3cmd put --recursive dir1 s3://s3tools-demo/some/path/
dir1/file1-1.txt -> s3://s3tools-demo/some/path/dir1/file1-1.txt  [1 of 2]
dir1/file1-2.txt -> s3://s3tools-demo/some/path/dir1/file1-2.txt  [2 of 2]

With directories there is one thing to watch out for – you can either upload the directory *and* its contents or just the contents. It all depends on how you specify the source.

To upload a directory and keep its name on the remote side specify the source without the trailing slash:
$ s3cmd put -r dir1 s3://s3tools-demo/some/path/
dir1/file1-1.txt -> s3://s3tools-demo/some/path/dir1/file1-1.txt  [1 of 2]
dir1/file1-2.txt -> s3://s3tools-demo/some/path/dir1/file1-2.txt  [2 of 2]

To upload just the contents, specify the directory it with a trailing slash:
$ s3cmd put -r dir1/ s3://s3tools-demo/some/path/
dir1/file1-1.txt -> s3://s3tools-demo/some/path/file1-1.txt  [1 of 2]
dir1/file1-2.txt -> s3://s3tools-demo/some/path/file1-2.txt  [2 of 2]

Important -- in both cases just the last part of the path name is taken into account. In the case of dir1 without trailing slash (which would be the same as, say, /dir1 in our case) the last part of the path is dir1 and that’s what’s used on the remote side, appended after s3://s3…/path/ to make s3://s3…/path/dir1/….

The above examples were built around put command. A bit more powerful is sync – the path names handling is the same as was just explained. However the important difference is that sync first checks the list and details of the files already present at the destination, compares with the local files and only uploads the ones that either are not present remotely or have a different size or md5 checksum. If you ran all the above examples you’ll get a similar output to the following one from a sync:

$ s3cmd sync  ./  s3://s3tools-demo/some/path/
dir2/file2-1.log -> s3://s3tools-demo/some/path/dir2/file2-1.log  [1 of 2]
dir2/file2-2.txt -> s3://s3tools-demo/some/path/dir2/file2-2.txt  [2 of 2]
As you can see only the files that we haven’t uploaded yet, that is those from dir2, were now sync‘ed.

--delete-removed deletes files that exist remotely but are no longer present locally (or perhaps just have different names here):

--skip-existing only uploads files with different names - doesn't check whether content has changed (not sure if it checks date)

Download from S3
================

Download from S3 with get and sync works pretty much along the same lines as explained above for upload. All the same rules apply.

Once the list of source files is compiled it is filtered through a set of exclude and include rules, in this order.

S3cmd has one exclude list and one include list. Each can hold any number of filename match patterns.
--exclude / --include  standard shell-style wildcards, enclose them in single apostrophes to avoid their expansion by the shell.
--rexclude / --rinclude  regular expression version of the above. You can get by with shell style wildcards, just use --exclude/--include
--exclude-from / --rexclude-from / --(r)include-from  specifies includes/excludes from a file instead of on the command line

All these parameters are equal in the sense that a file excluded by a --exclude-from rule can be put back into a game by, say, --rinclude rule.
One example to demonstrate the theory…
$ s3cmd sync --dry-run --exclude '*.txt' --include 'dir2/*' . s3://s3tools-demo/demo/
exclude: dir1/file1-1.txt
exclude: dir1/file1-2.txt
exclude: file0-2.txt
upload: ./dir2/file2-1.log -> s3://s3tools-demo/demo/dir2/file2-1.log
upload: ./dir2/file2-2.txt -> s3://s3tools-demo/demo/dir2/file2-2.txt
upload: ./file0-1.msg -> s3://s3tools-demo/demo/file0-1.msg
upload: ./file0-3.log -> s3://s3tools-demo/demo/file0-3.log
WARNING: Exiting now because of --dry-run

This exclude / _include filtering is available for put, get and sync. In the future del, cp and mv will support it as well.
